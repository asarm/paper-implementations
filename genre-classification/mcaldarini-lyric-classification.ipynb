{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4840139,"sourceType":"datasetVersion","datasetId":2805070}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nfrom tqdm import tqdm\nfrom sklearn.utils import resample\n\nfrom nltk.corpus import wordnet\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nimport string","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('wordnet')\n\nimport subprocess\n\n# Download and unzip wordnet\ntry:\n    nltk.data.find('wordnet.zip')\nexcept:\n    nltk.download('wordnet', download_dir='/kaggle/working/')\n    command = \"unzip /kaggle/working/corpora/wordnet.zip -d /kaggle/working/corpora\"\n    subprocess.run(command.split())\n    nltk.data.path.append('/kaggle/working/')\n    \nfrom nltk.corpus import wordnet","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:00:06.528814Z","iopub.execute_input":"2023-11-11T15:00:06.530456Z","iopub.status.idle":"2023-11-11T15:00:06.734131Z","shell.execute_reply.started":"2023-11-11T15:00:06.530398Z","shell.execute_reply":"2023-11-11T15:00:06.731490Z"},"trusted":true},"execution_count":341,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package wordnet to /kaggle/working/...\n[nltk_data]   Package wordnet is already up-to-date!\nArchive:  /kaggle/working/corpora/wordnet.zip\n","output_type":"stream"},{"name":"stderr","text":"replace /kaggle/working/corpora/wordnet/lexnames? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL\n(EOF or read error, treating as \"[N]one\" ...)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install eng-to-ipa\nimport eng_to_ipa as ipa","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:00:06.736224Z","iopub.execute_input":"2023-11-11T15:00:06.736628Z","iopub.status.idle":"2023-11-11T15:00:19.229250Z","shell.execute_reply.started":"2023-11-11T15:00:06.736597Z","shell.execute_reply":"2023-11-11T15:00:19.226525Z"},"trusted":true},"execution_count":342,"outputs":[{"name":"stdout","text":"Requirement already satisfied: eng-to-ipa in /opt/conda/lib/python3.10/site-packages (0.0.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"data_path = \"/kaggle/input/genius-song-lyrics-with-language-information/song_lyrics.csv\"\nchunks = pd.read_csv(data_path, iterator=True, chunksize=1000)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:00:19.232424Z","iopub.execute_input":"2023-11-11T15:00:19.232864Z","iopub.status.idle":"2023-11-11T15:00:19.251152Z","shell.execute_reply.started":"2023-11-11T15:00:19.232826Z","shell.execute_reply":"2023-11-11T15:00:19.249199Z"},"trusted":true},"execution_count":343,"outputs":[]},{"cell_type":"code","source":"new_data = pd.DataFrame()\nfor data in tqdm(chunks):\n    data_filtered = data[data.language == \"en\"][[\"title\", \"artist\", \"tag\", \"lyrics\"]]\n    \n    new_data = pd.concat([new_data, data_filtered])\n    \n    if min(new_data.tag.value_counts()) >= 3500:\n        break","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:00:19.257820Z","iopub.execute_input":"2023-11-11T15:00:19.258199Z","iopub.status.idle":"2023-11-11T15:00:40.770584Z","shell.execute_reply.started":"2023-11-11T15:00:19.258175Z","shell.execute_reply":"2023-11-11T15:00:40.768201Z"},"trusted":true},"execution_count":344,"outputs":[{"name":"stderr","text":"283it [00:21, 13.45it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"desired_size = min(new_data.tag.value_counts())\nnew_data.tag.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:00:40.772731Z","iopub.execute_input":"2023-11-11T15:00:40.773256Z","iopub.status.idle":"2023-11-11T15:00:40.817741Z","shell.execute_reply.started":"2023-11-11T15:00:40.773221Z","shell.execute_reply":"2023-11-11T15:00:40.815479Z"},"trusted":true},"execution_count":345,"outputs":[{"execution_count":345,"output_type":"execute_result","data":{"text/plain":"tag\nrap        134404\nmisc        55803\nrock        33676\npop          6949\ncountry      5646\nrb           3543\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"undersampled_data = pd.DataFrame()\n\nfor tag in set(new_data.tag):\n    class_df = new_data[new_data.tag == tag]\n    \n    undersampled = resample(class_df, replace=False, n_samples=desired_size, random_state=42)\n    undersampled_data = pd.concat([undersampled_data, undersampled])","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:00:40.820327Z","iopub.execute_input":"2023-11-11T15:00:40.821243Z","iopub.status.idle":"2023-11-11T15:00:41.041694Z","shell.execute_reply.started":"2023-11-11T15:00:40.821207Z","shell.execute_reply":"2023-11-11T15:00:41.040567Z"},"trusted":true},"execution_count":346,"outputs":[]},{"cell_type":"code","source":"undersampled_data = undersampled_data.sample(frac=1).reset_index(drop=True)\nundersampled_data.tag.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:00:41.043392Z","iopub.execute_input":"2023-11-11T15:00:41.043762Z","iopub.status.idle":"2023-11-11T15:00:41.069792Z","shell.execute_reply.started":"2023-11-11T15:00:41.043734Z","shell.execute_reply":"2023-11-11T15:00:41.067031Z"},"trusted":true},"execution_count":347,"outputs":[{"execution_count":347,"output_type":"execute_result","data":{"text/plain":"tag\nrock       3543\nrap        3543\nmisc       3543\npop        3543\ncountry    3543\nrb         3543\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"undersampled_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:00:41.071880Z","iopub.execute_input":"2023-11-11T15:00:41.072348Z","iopub.status.idle":"2023-11-11T15:00:41.093678Z","shell.execute_reply.started":"2023-11-11T15:00:41.072304Z","shell.execute_reply":"2023-11-11T15:00:41.091843Z"},"trusted":true},"execution_count":348,"outputs":[{"execution_count":348,"output_type":"execute_result","data":{"text/plain":"                               title                artist   tag  \\\n0  Love Me Like Im Not Made of Stone              Lykke Li  rock   \n1              Mudstained Troubadour                Opaque   rap   \n2     A Day In The Country Full Text         Anton Chekhov  misc   \n3                            My Same                 Adele   pop   \n4       Rosalind Helen And Her Child  Percy Bysshe Shelley  misc   \n\n                                              lyrics  \n0  [Produced By Björn Yttling, Greg Kurstin & Lyk...  \n1  [Verse 1: Opaque]\\nI walk in mud to my knees, ...  \n2  BETWEEN eight and nine o'clock in the morning....  \n3  [Intro]\\nAye, aye, aye-aye\\nAye, aye, aye-aye\\...  \n4  SCENE. THE SHORE OF THE LAKE OF COMO\\n\\nHELEN:...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>artist</th>\n      <th>tag</th>\n      <th>lyrics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Love Me Like Im Not Made of Stone</td>\n      <td>Lykke Li</td>\n      <td>rock</td>\n      <td>[Produced By Björn Yttling, Greg Kurstin &amp; Lyk...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Mudstained Troubadour</td>\n      <td>Opaque</td>\n      <td>rap</td>\n      <td>[Verse 1: Opaque]\\nI walk in mud to my knees, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A Day In The Country Full Text</td>\n      <td>Anton Chekhov</td>\n      <td>misc</td>\n      <td>BETWEEN eight and nine o'clock in the morning....</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>My Same</td>\n      <td>Adele</td>\n      <td>pop</td>\n      <td>[Intro]\\nAye, aye, aye-aye\\nAye, aye, aye-aye\\...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Rosalind Helen And Her Child</td>\n      <td>Percy Bysshe Shelley</td>\n      <td>misc</td>\n      <td>SCENE. THE SHORE OF THE LAKE OF COMO\\n\\nHELEN:...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data Processing","metadata":{}},{"cell_type":"markdown","source":"## Convert lowercase, remove extra information provided by data source, lemmatize and remove punctuations","metadata":{}},{"cell_type":"code","source":"# Convert to lowercase\nundersampled_data.lyrics = undersampled_data.lyrics.str.lower()","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:00:41.096067Z","iopub.execute_input":"2023-11-11T15:00:41.096459Z","iopub.status.idle":"2023-11-11T15:00:41.418317Z","shell.execute_reply.started":"2023-11-11T15:00:41.096424Z","shell.execute_reply":"2023-11-11T15:00:41.416145Z"},"trusted":true},"execution_count":349,"outputs":[]},{"cell_type":"code","source":"import re\n\n# rhe source website did not use a single format the demostrade new lines\ndef handleNewLine(text):\n    new_line_idxs = [match.start() for match in re.finditer(r'\\n', text)]\n    \n    lines = []\n    for idx in range(0, len(new_line_idxs)-1):\n        startIndex = new_line_idxs[idx]\n        endIndex = new_line_idxs[idx+1]\n        line = text[startIndex:endIndex]\n        line = line.split(\"\\n\")[1]\n        \n        if len(line)>0:\n            lines.append(line)\n    \n    return ' \\n '.join(lines)\n\nundersampled_data['lyrics'] = undersampled_data['lyrics'].apply(handleNewLine)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:00:41.427644Z","iopub.execute_input":"2023-11-11T15:00:41.428248Z","iopub.status.idle":"2023-11-11T15:00:42.452088Z","shell.execute_reply.started":"2023-11-11T15:00:41.428213Z","shell.execute_reply":"2023-11-11T15:00:42.449794Z"},"trusted":true},"execution_count":350,"outputs":[]},{"cell_type":"code","source":"# Remove extra notes\nundersampled_data['lyrics'] = undersampled_data['lyrics'].str.replace(r'\\[.*?\\]', '', regex=True)\nundersampled_data['lyrics'] = undersampled_data['lyrics'].str.replace(r'\\([^)]*\\)', '', regex=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:00:42.455710Z","iopub.execute_input":"2023-11-11T15:00:42.456231Z","iopub.status.idle":"2023-11-11T15:00:42.653502Z","shell.execute_reply.started":"2023-11-11T15:00:42.456200Z","shell.execute_reply":"2023-11-11T15:00:42.651760Z"},"trusted":true},"execution_count":351,"outputs":[]},{"cell_type":"code","source":"# Remove punctuations from the lyrics column except new line (\\n)\npunctuation = re.compile(r'[^\\w\\s\\n]+')\nundersampled_data['lyrics'] = undersampled_data['lyrics'].apply(lambda x: punctuation.sub('', x).strip())\nundersampled_data['lyrics'] = undersampled_data['lyrics'].str.replace(\" \\n  \\n \", \" \\n \")","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:00:42.655009Z","iopub.execute_input":"2023-11-11T15:00:42.655356Z","iopub.status.idle":"2023-11-11T15:00:44.419574Z","shell.execute_reply.started":"2023-11-11T15:00:42.655323Z","shell.execute_reply":"2023-11-11T15:00:44.418207Z"},"trusted":true},"execution_count":352,"outputs":[]},{"cell_type":"code","source":"random_song = np.random.randint(0, len(undersampled_data))\nundersampled_data.lyrics.iloc[random_song], undersampled_data.tag.iloc[random_song]","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:00:44.420977Z","iopub.execute_input":"2023-11-11T15:00:44.422298Z","iopub.status.idle":"2023-11-11T15:00:44.441562Z","shell.execute_reply.started":"2023-11-11T15:00:44.422236Z","shell.execute_reply":"2023-11-11T15:00:44.440132Z"},"trusted":true},"execution_count":353,"outputs":[{"execution_count":353,"output_type":"execute_result","data":{"text/plain":"('naah yeah rain comin we rollin never stollin still hollin girls fallin nerd ballin \\n saw this you on my list \\n sho for rollin beats on no \\n we gonna make it rain yo \\n medic medic fuck lil with static  \\n good flow trick yeah bro still rollin  yeah rain comin fuck weed throwin have loli have money what a goodness yeah  yeah freedom what a dream doom oooww scared hahah boom my music goes hard yeah i go hard yeah meeen my men amazin yeah p on board haha \\n uhhuuuuh yeaah this is crackhouse i m going back house fuck loss i am boss \\n pmugshot \\n smokin smokin lickin in the rockin ouw no big slim do show just creat a low no oww saw this law but im gonna creat some bow roll no just wanna get this now kill this bone im sho for this ho oww yoo haha we gonna make it rain yeaaah \\n yeaah call brother men and still havin doubt meen i have a fuckin lot of hater know this meeeen i am going to rock our money meeen yeaah rain comin need to know this until you blow with this yeahhhahah haha mama fuck you killa need to have some cola came with me and give me suny cause on my thang meeeen yeah haha you see the fuck i m in the rain  \\n saw this you on my list \\n sho for rollin beats on no',\n 'rap')"},"metadata":{}}]},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()\n\nfor index, row in tqdm(undersampled_data.iterrows()):\n    text = row['lyrics']\n    lemmatized_text = []\n    \n    # Lemmatize the text\n    for word in text.split(\" \"):\n        if word not in stop_words or word == \"\\n\":\n            if word == \"\\n\":\n                lemmatized_text.append(word)\n            else:\n                lemmatized_text.append(lemmatizer.lemmatize(word))\n    \n    txt = ' '.join(lemmatized_text)\n    undersampled_data.loc[index, 'lyrics'] = \" \\n \" + txt","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:00:44.443018Z","iopub.execute_input":"2023-11-11T15:00:44.443403Z","iopub.status.idle":"2023-11-11T15:01:22.200138Z","shell.execute_reply.started":"2023-11-11T15:00:44.443373Z","shell.execute_reply":"2023-11-11T15:01:22.199279Z"},"trusted":true},"execution_count":354,"outputs":[{"name":"stderr","text":"21258it [00:37, 563.21it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"undersampled_data.reset_index(inplace=True, drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:01:22.201261Z","iopub.execute_input":"2023-11-11T15:01:22.201594Z","iopub.status.idle":"2023-11-11T15:01:22.209602Z","shell.execute_reply.started":"2023-11-11T15:01:22.201568Z","shell.execute_reply":"2023-11-11T15:01:22.207497Z"},"trusted":true},"execution_count":355,"outputs":[]},{"cell_type":"code","source":"undersampled_data.lyrics.iloc[random_song], undersampled_data.tag.iloc[random_song]","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:01:22.211730Z","iopub.execute_input":"2023-11-11T15:01:22.212138Z","iopub.status.idle":"2023-11-11T15:01:22.227173Z","shell.execute_reply.started":"2023-11-11T15:01:22.212111Z","shell.execute_reply":"2023-11-11T15:01:22.224871Z"},"trusted":true},"execution_count":356,"outputs":[{"execution_count":356,"output_type":"execute_result","data":{"text/plain":"(' \\n naah yeah rain comin rollin never stollin still hollin girl fallin nerd ballin \\n saw list \\n sho rollin beat \\n gonna make rain yo \\n medic medic fuck lil static  \\n good flow trick yeah bro still rollin  yeah rain comin fuck weed throwin loli money goodness yeah  yeah freedom dream doom oooww scared hahah boom music go hard yeah go hard yeah meeen men amazin yeah p board haha \\n uhhuuuuh yeaah crackhouse going back house fuck loss bos \\n pmugshot \\n smokin smokin lickin rockin ouw big slim show creat low oww saw law im gonna creat bow roll wanna get kill bone im sho ho oww yoo haha gonna make rain yeaaah \\n yeaah call brother men still havin doubt meen fuckin lot hater know meeeen going rock money meeen yeaah rain comin need know blow yeahhhahah haha mama fuck killa need cola came give suny cause thang meeeen yeah haha see fuck rain  \\n saw list \\n sho rollin beat',\n 'rap')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Split each line","metadata":{}},{"cell_type":"code","source":"def split_lyrics(lyric):\n  \"\"\"Splits a lyric into a list of lines.\"\"\"\n  lines = []\n  try:\n      splt = lyric.split(\"\\n\")\n      for line in splt:\n        line = line.strip()\n\n        if len(line) > 1:\n          lines.append(line)\n\n      return lines\n  except:\n        return None\n\nundersampled_data[\"lines\"] = undersampled_data.lyrics.apply(split_lyrics)\nundersampled_data.reset_index(inplace=True, drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:01:22.231312Z","iopub.execute_input":"2023-11-11T15:01:22.231907Z","iopub.status.idle":"2023-11-11T15:01:22.631006Z","shell.execute_reply.started":"2023-11-11T15:01:22.231864Z","shell.execute_reply":"2023-11-11T15:01:22.628490Z"},"trusted":true},"execution_count":357,"outputs":[]},{"cell_type":"code","source":"undersampled_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:01:22.635368Z","iopub.execute_input":"2023-11-11T15:01:22.635872Z","iopub.status.idle":"2023-11-11T15:01:22.654374Z","shell.execute_reply.started":"2023-11-11T15:01:22.635842Z","shell.execute_reply":"2023-11-11T15:01:22.652499Z"},"trusted":true},"execution_count":358,"outputs":[{"execution_count":358,"output_type":"execute_result","data":{"text/plain":"                               title                artist   tag  \\\n0  Love Me Like Im Not Made of Stone              Lykke Li  rock   \n1              Mudstained Troubadour                Opaque   rap   \n2     A Day In The Country Full Text         Anton Chekhov  misc   \n3                            My Same                 Adele   pop   \n4       Rosalind Helen And Her Child  Percy Bysshe Shelley  misc   \n\n                                              lyrics  \\\n0   \\n there heart cannot hide \\n there beat cant...   \n1   \\n walk mud knee cloudy dark \\n spark start b...   \n2   \\n dark leadencoloured mass creeping sky towa...   \n3   \\n aye aye ayeaye \\n aye aye ayeaye \\n aye ay...   \n4   \\n helen \\n come hither sweet rosalind \\n ti ...   \n\n                                               lines  \n0  [there heart cannot hide, there beat cant deny...  \n1  [walk mud knee cloudy dark, spark start bark a...  \n2  [dark leadencoloured mass creeping sky towards...  \n3  [aye aye ayeaye, aye aye ayeaye, aye aye ayeay...  \n4  [helen, come hither sweet rosalind, ti long si...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>artist</th>\n      <th>tag</th>\n      <th>lyrics</th>\n      <th>lines</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Love Me Like Im Not Made of Stone</td>\n      <td>Lykke Li</td>\n      <td>rock</td>\n      <td>\\n there heart cannot hide \\n there beat cant...</td>\n      <td>[there heart cannot hide, there beat cant deny...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Mudstained Troubadour</td>\n      <td>Opaque</td>\n      <td>rap</td>\n      <td>\\n walk mud knee cloudy dark \\n spark start b...</td>\n      <td>[walk mud knee cloudy dark, spark start bark a...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A Day In The Country Full Text</td>\n      <td>Anton Chekhov</td>\n      <td>misc</td>\n      <td>\\n dark leadencoloured mass creeping sky towa...</td>\n      <td>[dark leadencoloured mass creeping sky towards...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>My Same</td>\n      <td>Adele</td>\n      <td>pop</td>\n      <td>\\n aye aye ayeaye \\n aye aye ayeaye \\n aye ay...</td>\n      <td>[aye aye ayeaye, aye aye ayeaye, aye aye ayeay...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Rosalind Helen And Her Child</td>\n      <td>Percy Bysshe Shelley</td>\n      <td>misc</td>\n      <td>\\n helen \\n come hither sweet rosalind \\n ti ...</td>\n      <td>[helen, come hither sweet rosalind, ti long si...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"undersampled_data.iloc[random_song]","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:01:22.656216Z","iopub.execute_input":"2023-11-11T15:01:22.657682Z","iopub.status.idle":"2023-11-11T15:01:22.672562Z","shell.execute_reply.started":"2023-11-11T15:01:22.657599Z","shell.execute_reply":"2023-11-11T15:01:22.670610Z"},"trusted":true},"execution_count":359,"outputs":[{"execution_count":359,"output_type":"execute_result","data":{"text/plain":"title                                      Rain ft PMugShot\nartist                                             The Last\ntag                                                     rap\nlyrics     \\n naah yeah rain comin rollin never stollin ...\nlines     [naah yeah rain comin rollin never stollin sti...\nName: 14505, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"## Generate list of tokens","metadata":{}},{"cell_type":"code","source":"def split_tokens(lines):\n    tokens = []\n    \n    try:\n        for line in lines:\n            tokens.append(word_tokenize(line))\n\n        return tokens\n    except:\n        return None\n\nundersampled_data[\"tokens\"] = undersampled_data.lines.apply(split_tokens)\nundersampled_data.reset_index(inplace=True, drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:01:22.675167Z","iopub.execute_input":"2023-11-11T15:01:22.675887Z","iopub.status.idle":"2023-11-11T15:02:38.723194Z","shell.execute_reply.started":"2023-11-11T15:01:22.675844Z","shell.execute_reply":"2023-11-11T15:02:38.721317Z"},"trusted":true},"execution_count":360,"outputs":[]},{"cell_type":"markdown","source":"# Feature Exctraction","metadata":{}},{"cell_type":"markdown","source":"## Textual Features\n\nTotal words, unique words, total chars, total lines, avg word per line","metadata":{}},{"cell_type":"code","source":"for idx, tokens in tqdm(enumerate(list(undersampled_data.tokens))):\n    total_lines = len(tokens)\n    \n    total_word = 0\n    unique_words = []\n    total_chars = 0\n    \n    for line in tokens:\n        total_word += len(line)\n        \n        for token in line:\n            total_chars += len(token)\n            if token not in unique_words:\n                unique_words.append(token)\n            \n    if total_lines != 0:\n        \n        avg_word_per_line = total_word / total_lines\n\n        undersampled_data.at[idx, \"total_lines\"] = total_lines\n        undersampled_data.at[idx, \"total_word\"] = total_word\n        undersampled_data.at[idx, \"unique_words\"] = len(unique_words)\n        undersampled_data.at[idx, \"total_chars\"] = total_chars\n        undersampled_data.at[idx, \"avg_word_per_line\"] = avg_word_per_line","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:05:08.401287Z","iopub.execute_input":"2023-11-11T15:05:08.401623Z","iopub.status.idle":"2023-11-11T15:05:24.813813Z","shell.execute_reply.started":"2023-11-11T15:05:08.401599Z","shell.execute_reply":"2023-11-11T15:05:24.811868Z"},"trusted":true},"execution_count":369,"outputs":[{"name":"stderr","text":"21258it [00:16, 1296.71it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"undersampled_data = undersampled_data.dropna().reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:06:10.988131Z","iopub.execute_input":"2023-11-11T15:06:10.989847Z","iopub.status.idle":"2023-11-11T15:06:11.030413Z","shell.execute_reply.started":"2023-11-11T15:06:10.989806Z","shell.execute_reply":"2023-11-11T15:06:11.028946Z"},"trusted":true},"execution_count":373,"outputs":[]},{"cell_type":"code","source":"undersampled_data[[\"tag\", \"total_word\", \"avg_word_per_line\", \"unique_words\", \"total_chars\"]].groupby(\"tag\").mean()","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:06:25.574133Z","iopub.execute_input":"2023-11-11T15:06:25.574947Z","iopub.status.idle":"2023-11-11T15:06:25.600494Z","shell.execute_reply.started":"2023-11-11T15:06:25.574906Z","shell.execute_reply":"2023-11-11T15:06:25.598478Z"},"trusted":true},"execution_count":375,"outputs":[{"execution_count":375,"output_type":"execute_result","data":{"text/plain":"         total_word  avg_word_per_line  unique_words  total_chars\ntag                                                              \ncountry  107.957933           4.018459     62.681818   511.817617\nmisc     604.418071          18.393448    321.532249  3550.735038\npop      154.300282           3.466503     67.094350   716.616384\nrap      264.762895           5.218872    171.810772  1273.848105\nrb       181.554489           3.611197     80.861378   822.165443\nrock     111.692633           3.502165     60.471916   536.243297","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>total_word</th>\n      <th>avg_word_per_line</th>\n      <th>unique_words</th>\n      <th>total_chars</th>\n    </tr>\n    <tr>\n      <th>tag</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>country</th>\n      <td>107.957933</td>\n      <td>4.018459</td>\n      <td>62.681818</td>\n      <td>511.817617</td>\n    </tr>\n    <tr>\n      <th>misc</th>\n      <td>604.418071</td>\n      <td>18.393448</td>\n      <td>321.532249</td>\n      <td>3550.735038</td>\n    </tr>\n    <tr>\n      <th>pop</th>\n      <td>154.300282</td>\n      <td>3.466503</td>\n      <td>67.094350</td>\n      <td>716.616384</td>\n    </tr>\n    <tr>\n      <th>rap</th>\n      <td>264.762895</td>\n      <td>5.218872</td>\n      <td>171.810772</td>\n      <td>1273.848105</td>\n    </tr>\n    <tr>\n      <th>rb</th>\n      <td>181.554489</td>\n      <td>3.611197</td>\n      <td>80.861378</td>\n      <td>822.165443</td>\n    </tr>\n    <tr>\n      <th>rock</th>\n      <td>111.692633</td>\n      <td>3.502165</td>\n      <td>60.471916</td>\n      <td>536.243297</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Syllable Features\nTotal syllables, avg syllables per word, avg syllables per line, flesch reading ease ","metadata":{}},{"cell_type":"code","source":"!pip install syllables\n!pip install py-readability-metrics","metadata":{"execution":{"iopub.status.busy":"2023-11-11T12:13:57.614629Z","iopub.execute_input":"2023-11-11T12:13:57.615018Z","iopub.status.idle":"2023-11-11T12:14:19.023378Z","shell.execute_reply.started":"2023-11-11T12:13:57.614985Z","shell.execute_reply":"2023-11-11T12:14:19.021649Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Collecting syllables\n  Downloading syllables-1.0.9-py3-none-any.whl (15 kB)\nRequirement already satisfied: cmudict<2.0.0,>=1.0.11 in /opt/conda/lib/python3.10/site-packages (from syllables) (1.0.13)\nRequirement already satisfied: importlib-metadata<7.0,>=5.1 in /opt/conda/lib/python3.10/site-packages (from syllables) (6.7.0)\nCollecting importlib-metadata<7.0,>=5.1 (from syllables)\n  Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\nRequirement already satisfied: importlib-resources<6.0.0,>=5.10.1 in /opt/conda/lib/python3.10/site-packages (from cmudict<2.0.0,>=1.0.11->syllables) (5.12.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7.0,>=5.1->syllables) (3.15.0)\nInstalling collected packages: importlib-metadata, syllables\n  Attempting uninstall: importlib-metadata\n    Found existing installation: importlib-metadata 6.7.0\n    Uninstalling importlib-metadata-6.7.0:\n      Successfully uninstalled importlib-metadata-6.7.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nopentelemetry-api 1.18.0 requires importlib-metadata~=6.0.0, but you have importlib-metadata 5.2.0 which is incompatible.\nyapf 0.40.1 requires importlib-metadata>=6.6.0, but you have importlib-metadata 5.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed importlib-metadata-5.2.0 syllables-1.0.9\nCollecting py-readability-metrics\n  Downloading py_readability_metrics-1.4.5-py3-none-any.whl (26 kB)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from py-readability-metrics) (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->py-readability-metrics) (1.16.0)\nInstalling collected packages: py-readability-metrics\nSuccessfully installed py-readability-metrics-1.4.5\n","output_type":"stream"}]},{"cell_type":"code","source":"from readability import Readability\nimport syllables","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:06:28.295071Z","iopub.execute_input":"2023-11-11T15:06:28.296321Z","iopub.status.idle":"2023-11-11T15:06:28.303499Z","shell.execute_reply.started":"2023-11-11T15:06:28.296246Z","shell.execute_reply":"2023-11-11T15:06:28.300865Z"},"trusted":true},"execution_count":376,"outputs":[]},{"cell_type":"code","source":"for idx, line in tqdm(enumerate(list(undersampled_data.lines))):\n    total = 0\n    \n    for sep_line in line:\n        syllable_count = syllables.estimate(sep_line)\n        total += syllable_count\n    \n    try:\n        full_text = ' '.join(line)\n        if len(full_text.split()) >= 100:\n            r = Readability(full_text)\n            r_score = r.flesch_kincaid().score\n        else:\n            r_score = 100\n\n        undersampled_data.at[idx, \"avg_syllables_per_line\"] = total / len(line)\n        undersampled_data.at[idx, \"avg_syllables_per_word\"] = total / len(' '.join(line).split(' '))\n        undersampled_data.at[idx, \"sum_syllables\"] = total\n    except:\n        r_score = None\n        \n    undersampled_data.at[idx, \"readability\"] = r_score","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:06:35.584080Z","iopub.execute_input":"2023-11-11T15:06:35.584666Z","iopub.status.idle":"2023-11-11T15:12:17.489336Z","shell.execute_reply.started":"2023-11-11T15:06:35.584602Z","shell.execute_reply":"2023-11-11T15:12:17.487374Z"},"trusted":true},"execution_count":377,"outputs":[{"name":"stderr","text":"21118it [05:41, 61.77it/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"undersampled_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:20:28.312915Z","iopub.execute_input":"2023-11-11T15:20:28.313384Z","iopub.status.idle":"2023-11-11T15:20:28.416311Z","shell.execute_reply.started":"2023-11-11T15:20:28.313352Z","shell.execute_reply":"2023-11-11T15:20:28.414421Z"},"trusted":true},"execution_count":378,"outputs":[{"execution_count":378,"output_type":"execute_result","data":{"text/plain":"                               title                artist   tag  \\\n0  Love Me Like Im Not Made of Stone              Lykke Li  rock   \n1              Mudstained Troubadour                Opaque   rap   \n2     A Day In The Country Full Text         Anton Chekhov  misc   \n3                            My Same                 Adele   pop   \n4       Rosalind Helen And Her Child  Percy Bysshe Shelley  misc   \n\n                                              lyrics  \\\n0   \\n there heart cannot hide \\n there beat cant...   \n1   \\n walk mud knee cloudy dark \\n spark start b...   \n2   \\n dark leadencoloured mass creeping sky towa...   \n3   \\n aye aye ayeaye \\n aye aye ayeaye \\n aye ay...   \n4   \\n helen \\n come hither sweet rosalind \\n ti ...   \n\n                                               lines  \\\n0  [there heart cannot hide, there beat cant deny...   \n1  [walk mud knee cloudy dark, spark start bark a...   \n2  [dark leadencoloured mass creeping sky towards...   \n3  [aye aye ayeaye, aye aye ayeaye, aye aye ayeay...   \n4  [helen, come hither sweet rosalind, ti long si...   \n\n                                              tokens  total_lines  total_word  \\\n0  [[there, heart, can, not, hide], [there, beat,...         29.0       121.0   \n1  [[walk, mud, knee, cloudy, dark], [spark, star...         55.0       276.0   \n2  [[dark, leadencoloured, mass, creeping, sky, t...         65.0      1131.0   \n3  [[aye, aye, ayeaye], [aye, aye, ayeaye], [aye,...         40.0       164.0   \n4  [[helen], [come, hither, sweet, rosalind], [ti...       1333.0      4848.0   \n\n   unique_words  total_chars  avg_word_per_line  avg_syllables_per_line  \\\n0          48.0        504.0           4.172414                6.551724   \n1         244.0       1407.0           5.018182                8.581818   \n2         620.0       6125.0          17.400000               30.153846   \n3          65.0        826.0           4.100000                6.725000   \n4        1762.0      25125.0           3.636909                6.012753   \n\n   avg_syllables_per_word  sum_syllables  readability  \n0                1.583333          190.0    44.465000  \n1                1.710145          472.0   107.460290  \n2                1.666667         1960.0   433.491503  \n3                1.640244          269.0    65.005610  \n4                1.655650         8015.0  1841.608343  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>artist</th>\n      <th>tag</th>\n      <th>lyrics</th>\n      <th>lines</th>\n      <th>tokens</th>\n      <th>total_lines</th>\n      <th>total_word</th>\n      <th>unique_words</th>\n      <th>total_chars</th>\n      <th>avg_word_per_line</th>\n      <th>avg_syllables_per_line</th>\n      <th>avg_syllables_per_word</th>\n      <th>sum_syllables</th>\n      <th>readability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Love Me Like Im Not Made of Stone</td>\n      <td>Lykke Li</td>\n      <td>rock</td>\n      <td>\\n there heart cannot hide \\n there beat cant...</td>\n      <td>[there heart cannot hide, there beat cant deny...</td>\n      <td>[[there, heart, can, not, hide], [there, beat,...</td>\n      <td>29.0</td>\n      <td>121.0</td>\n      <td>48.0</td>\n      <td>504.0</td>\n      <td>4.172414</td>\n      <td>6.551724</td>\n      <td>1.583333</td>\n      <td>190.0</td>\n      <td>44.465000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Mudstained Troubadour</td>\n      <td>Opaque</td>\n      <td>rap</td>\n      <td>\\n walk mud knee cloudy dark \\n spark start b...</td>\n      <td>[walk mud knee cloudy dark, spark start bark a...</td>\n      <td>[[walk, mud, knee, cloudy, dark], [spark, star...</td>\n      <td>55.0</td>\n      <td>276.0</td>\n      <td>244.0</td>\n      <td>1407.0</td>\n      <td>5.018182</td>\n      <td>8.581818</td>\n      <td>1.710145</td>\n      <td>472.0</td>\n      <td>107.460290</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A Day In The Country Full Text</td>\n      <td>Anton Chekhov</td>\n      <td>misc</td>\n      <td>\\n dark leadencoloured mass creeping sky towa...</td>\n      <td>[dark leadencoloured mass creeping sky towards...</td>\n      <td>[[dark, leadencoloured, mass, creeping, sky, t...</td>\n      <td>65.0</td>\n      <td>1131.0</td>\n      <td>620.0</td>\n      <td>6125.0</td>\n      <td>17.400000</td>\n      <td>30.153846</td>\n      <td>1.666667</td>\n      <td>1960.0</td>\n      <td>433.491503</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>My Same</td>\n      <td>Adele</td>\n      <td>pop</td>\n      <td>\\n aye aye ayeaye \\n aye aye ayeaye \\n aye ay...</td>\n      <td>[aye aye ayeaye, aye aye ayeaye, aye aye ayeay...</td>\n      <td>[[aye, aye, ayeaye], [aye, aye, ayeaye], [aye,...</td>\n      <td>40.0</td>\n      <td>164.0</td>\n      <td>65.0</td>\n      <td>826.0</td>\n      <td>4.100000</td>\n      <td>6.725000</td>\n      <td>1.640244</td>\n      <td>269.0</td>\n      <td>65.005610</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Rosalind Helen And Her Child</td>\n      <td>Percy Bysshe Shelley</td>\n      <td>misc</td>\n      <td>\\n helen \\n come hither sweet rosalind \\n ti ...</td>\n      <td>[helen, come hither sweet rosalind, ti long si...</td>\n      <td>[[helen], [come, hither, sweet, rosalind], [ti...</td>\n      <td>1333.0</td>\n      <td>4848.0</td>\n      <td>1762.0</td>\n      <td>25125.0</td>\n      <td>3.636909</td>\n      <td>6.012753</td>\n      <td>1.655650</td>\n      <td>8015.0</td>\n      <td>1841.608343</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Line-Syllable Similarity","metadata":{}},{"cell_type":"code","source":"undersampled_data[\"line_similarity\"] = None\n\nfor idx, line in tqdm(enumerate(list(undersampled_data.tokens))):\n    similarity_list = []\n    for sep_line_id in range(1, len(line)):\n        currentLineLen = len(line[sep_line_id])\n        prevLineLen = len(line[sep_line_id-1])\n        \n        if currentLineLen == 0 or prevLineLen == 0:\n            pass\n        else:\n            similarity = 1 - (abs(currentLineLen - prevLineLen) / max(currentLineLen, prevLineLen))\n            similarity_list.append(similarity)\n            \n    undersampled_data.at[idx, \"line_similarity\"] = np.mean(similarity_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:20:33.232728Z","iopub.execute_input":"2023-11-11T15:20:33.233169Z","iopub.status.idle":"2023-11-11T15:20:35.092566Z","shell.execute_reply.started":"2023-11-11T15:20:33.233134Z","shell.execute_reply":"2023-11-11T15:20:35.090166Z"},"trusted":true},"execution_count":379,"outputs":[{"name":"stderr","text":"0it [00:00, ?it/s]/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n  return _methods._mean(a, axis=axis, dtype=dtype,\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n  ret = ret.dtype.type(ret / rcount)\n21118it [00:01, 11669.08it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"undersampled_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:20:37.427512Z","iopub.execute_input":"2023-11-11T15:20:37.427930Z","iopub.status.idle":"2023-11-11T15:20:37.532244Z","shell.execute_reply.started":"2023-11-11T15:20:37.427896Z","shell.execute_reply":"2023-11-11T15:20:37.530764Z"},"trusted":true},"execution_count":380,"outputs":[{"execution_count":380,"output_type":"execute_result","data":{"text/plain":"                               title                artist   tag  \\\n0  Love Me Like Im Not Made of Stone              Lykke Li  rock   \n1              Mudstained Troubadour                Opaque   rap   \n2     A Day In The Country Full Text         Anton Chekhov  misc   \n3                            My Same                 Adele   pop   \n4       Rosalind Helen And Her Child  Percy Bysshe Shelley  misc   \n\n                                              lyrics  \\\n0   \\n there heart cannot hide \\n there beat cant...   \n1   \\n walk mud knee cloudy dark \\n spark start b...   \n2   \\n dark leadencoloured mass creeping sky towa...   \n3   \\n aye aye ayeaye \\n aye aye ayeaye \\n aye ay...   \n4   \\n helen \\n come hither sweet rosalind \\n ti ...   \n\n                                               lines  \\\n0  [there heart cannot hide, there beat cant deny...   \n1  [walk mud knee cloudy dark, spark start bark a...   \n2  [dark leadencoloured mass creeping sky towards...   \n3  [aye aye ayeaye, aye aye ayeaye, aye aye ayeay...   \n4  [helen, come hither sweet rosalind, ti long si...   \n\n                                              tokens  total_lines  total_word  \\\n0  [[there, heart, can, not, hide], [there, beat,...         29.0       121.0   \n1  [[walk, mud, knee, cloudy, dark], [spark, star...         55.0       276.0   \n2  [[dark, leadencoloured, mass, creeping, sky, t...         65.0      1131.0   \n3  [[aye, aye, ayeaye], [aye, aye, ayeaye], [aye,...         40.0       164.0   \n4  [[helen], [come, hither, sweet, rosalind], [ti...       1333.0      4848.0   \n\n   unique_words  total_chars  avg_word_per_line  avg_syllables_per_line  \\\n0          48.0        504.0           4.172414                6.551724   \n1         244.0       1407.0           5.018182                8.581818   \n2         620.0       6125.0          17.400000               30.153846   \n3          65.0        826.0           4.100000                6.725000   \n4        1762.0      25125.0           3.636909                6.012753   \n\n   avg_syllables_per_word  sum_syllables  readability line_similarity  \n0                1.583333          190.0    44.465000        0.718452  \n1                1.710145          472.0   107.460290        0.746715  \n2                1.666667         1960.0   433.491503        0.458772  \n3                1.640244          269.0    65.005610        0.732234  \n4                1.655650         8015.0  1841.608343        0.765212  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>artist</th>\n      <th>tag</th>\n      <th>lyrics</th>\n      <th>lines</th>\n      <th>tokens</th>\n      <th>total_lines</th>\n      <th>total_word</th>\n      <th>unique_words</th>\n      <th>total_chars</th>\n      <th>avg_word_per_line</th>\n      <th>avg_syllables_per_line</th>\n      <th>avg_syllables_per_word</th>\n      <th>sum_syllables</th>\n      <th>readability</th>\n      <th>line_similarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Love Me Like Im Not Made of Stone</td>\n      <td>Lykke Li</td>\n      <td>rock</td>\n      <td>\\n there heart cannot hide \\n there beat cant...</td>\n      <td>[there heart cannot hide, there beat cant deny...</td>\n      <td>[[there, heart, can, not, hide], [there, beat,...</td>\n      <td>29.0</td>\n      <td>121.0</td>\n      <td>48.0</td>\n      <td>504.0</td>\n      <td>4.172414</td>\n      <td>6.551724</td>\n      <td>1.583333</td>\n      <td>190.0</td>\n      <td>44.465000</td>\n      <td>0.718452</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Mudstained Troubadour</td>\n      <td>Opaque</td>\n      <td>rap</td>\n      <td>\\n walk mud knee cloudy dark \\n spark start b...</td>\n      <td>[walk mud knee cloudy dark, spark start bark a...</td>\n      <td>[[walk, mud, knee, cloudy, dark], [spark, star...</td>\n      <td>55.0</td>\n      <td>276.0</td>\n      <td>244.0</td>\n      <td>1407.0</td>\n      <td>5.018182</td>\n      <td>8.581818</td>\n      <td>1.710145</td>\n      <td>472.0</td>\n      <td>107.460290</td>\n      <td>0.746715</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A Day In The Country Full Text</td>\n      <td>Anton Chekhov</td>\n      <td>misc</td>\n      <td>\\n dark leadencoloured mass creeping sky towa...</td>\n      <td>[dark leadencoloured mass creeping sky towards...</td>\n      <td>[[dark, leadencoloured, mass, creeping, sky, t...</td>\n      <td>65.0</td>\n      <td>1131.0</td>\n      <td>620.0</td>\n      <td>6125.0</td>\n      <td>17.400000</td>\n      <td>30.153846</td>\n      <td>1.666667</td>\n      <td>1960.0</td>\n      <td>433.491503</td>\n      <td>0.458772</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>My Same</td>\n      <td>Adele</td>\n      <td>pop</td>\n      <td>\\n aye aye ayeaye \\n aye aye ayeaye \\n aye ay...</td>\n      <td>[aye aye ayeaye, aye aye ayeaye, aye aye ayeay...</td>\n      <td>[[aye, aye, ayeaye], [aye, aye, ayeaye], [aye,...</td>\n      <td>40.0</td>\n      <td>164.0</td>\n      <td>65.0</td>\n      <td>826.0</td>\n      <td>4.100000</td>\n      <td>6.725000</td>\n      <td>1.640244</td>\n      <td>269.0</td>\n      <td>65.005610</td>\n      <td>0.732234</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Rosalind Helen And Her Child</td>\n      <td>Percy Bysshe Shelley</td>\n      <td>misc</td>\n      <td>\\n helen \\n come hither sweet rosalind \\n ti ...</td>\n      <td>[helen, come hither sweet rosalind, ti long si...</td>\n      <td>[[helen], [come, hither, sweet, rosalind], [ti...</td>\n      <td>1333.0</td>\n      <td>4848.0</td>\n      <td>1762.0</td>\n      <td>25125.0</td>\n      <td>3.636909</td>\n      <td>6.012753</td>\n      <td>1.655650</td>\n      <td>8015.0</td>\n      <td>1841.608343</td>\n      <td>0.765212</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"undersampled_data[[\"tag\", \"line_similarity\"]].groupby(\"tag\").mean()","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:20:40.761318Z","iopub.execute_input":"2023-11-11T15:20:40.761712Z","iopub.status.idle":"2023-11-11T15:20:40.787396Z","shell.execute_reply.started":"2023-11-11T15:20:40.761680Z","shell.execute_reply":"2023-11-11T15:20:40.786301Z"},"trusted":true},"execution_count":381,"outputs":[{"execution_count":381,"output_type":"execute_result","data":{"text/plain":"        line_similarity\ntag                    \ncountry        0.714037\nmisc           0.629427\npop            0.701177\nrap            0.709364\nrb             0.691597\nrock           0.709807","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>line_similarity</th>\n    </tr>\n    <tr>\n      <th>tag</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>country</th>\n      <td>0.714037</td>\n    </tr>\n    <tr>\n      <th>misc</th>\n      <td>0.629427</td>\n    </tr>\n    <tr>\n      <th>pop</th>\n      <td>0.701177</td>\n    </tr>\n    <tr>\n      <th>rap</th>\n      <td>0.709364</td>\n    </tr>\n    <tr>\n      <th>rb</th>\n      <td>0.691597</td>\n    </tr>\n    <tr>\n      <th>rock</th>\n      <td>0.709807</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Vocab Features\nTf-idf vectors","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ndef merge_strings(row):\n    return ' '.join(row)\n\ncorpus = []\nfor lyric in undersampled_data.lyrics:\n    filtered_words = [word for word in lyric.split() if 3 <= len(word) <= 12]\n    \n    corpus.append(' '.join(filtered_words))\n    \nvectorizer = TfidfVectorizer(min_df=50, max_df=0.5)\ntfidf_matrix  = vectorizer.fit_transform(corpus)\n\ntfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\ntfidf_df['tag'] = undersampled_data['tag']\navg_tfidf_by_genre = tfidf_df.groupby('tag').mean()","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:20:45.396007Z","iopub.execute_input":"2023-11-11T15:20:45.396511Z","iopub.status.idle":"2023-11-11T15:20:51.729264Z","shell.execute_reply.started":"2023-11-11T15:20:45.396468Z","shell.execute_reply":"2023-11-11T15:20:51.726777Z"},"trusted":true},"execution_count":382,"outputs":[]},{"cell_type":"code","source":"avg_tfidf_by_genre","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:20:56.969691Z","iopub.execute_input":"2023-11-11T15:20:56.971124Z","iopub.status.idle":"2023-11-11T15:20:56.996522Z","shell.execute_reply.started":"2023-11-11T15:20:56.971087Z","shell.execute_reply":"2023-11-11T15:20:56.995193Z"},"trusted":true},"execution_count":383,"outputs":[{"execution_count":383,"output_type":"execute_result","data":{"text/plain":"              100       1st       3rd       911   abandon  abandoned  \\\ntag                                                                    \ncountry  0.000170  0.000076  0.000036  0.000028  0.000043   0.000250   \nmisc     0.000452  0.000603  0.000411  0.000335  0.000529   0.001109   \npop      0.000247  0.000000  0.000000  0.000081  0.000254   0.000061   \nrap      0.001971  0.000713  0.001026  0.000590  0.000286   0.000394   \nrb       0.000242  0.000341  0.000174  0.000320  0.000178   0.000117   \nrock     0.000148  0.000000  0.000157  0.000028  0.000153   0.000500   \n\n            abide   ability      able    aboard  ...  youngest     youre  \\\ntag                                              ...                       \ncountry  0.000096  0.000022  0.000558  0.000190  ...  0.000105  0.026920   \nmisc     0.001035  0.001380  0.004913  0.000454  ...  0.000398  0.003879   \npop      0.000029  0.000000  0.000417  0.000126  ...  0.000000  0.039320   \nrap      0.000298  0.000476  0.001011  0.000305  ...  0.000224  0.016065   \nrb       0.000143  0.000213  0.000605  0.000014  ...  0.000081  0.035421   \nrock     0.000105  0.000107  0.000355  0.000319  ...  0.000070  0.026819   \n\n             yous     youth  youthful     youve       yup      zeal      zero  \\\ntag                                                                             \ncountry  0.000213  0.000413  0.000000  0.011927  0.000000  0.000000  0.000327   \nmisc     0.000176  0.005351  0.000929  0.001830  0.000000  0.000775  0.000446   \npop      0.000474  0.000832  0.000000  0.010012  0.000181  0.000000  0.000676   \nrap      0.001182  0.001577  0.000075  0.002928  0.001504  0.000092  0.000961   \nrb       0.000834  0.000330  0.000034  0.008876  0.000244  0.000000  0.000436   \nrock     0.000188  0.000797  0.000235  0.011931  0.000056  0.000016  0.000540   \n\n             zone  \ntag                \ncountry  0.000199  \nmisc     0.000544  \npop      0.000655  \nrap      0.003907  \nrb       0.000832  \nrock     0.000176  \n\n[6 rows x 6268 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>100</th>\n      <th>1st</th>\n      <th>3rd</th>\n      <th>911</th>\n      <th>abandon</th>\n      <th>abandoned</th>\n      <th>abide</th>\n      <th>ability</th>\n      <th>able</th>\n      <th>aboard</th>\n      <th>...</th>\n      <th>youngest</th>\n      <th>youre</th>\n      <th>yous</th>\n      <th>youth</th>\n      <th>youthful</th>\n      <th>youve</th>\n      <th>yup</th>\n      <th>zeal</th>\n      <th>zero</th>\n      <th>zone</th>\n    </tr>\n    <tr>\n      <th>tag</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>country</th>\n      <td>0.000170</td>\n      <td>0.000076</td>\n      <td>0.000036</td>\n      <td>0.000028</td>\n      <td>0.000043</td>\n      <td>0.000250</td>\n      <td>0.000096</td>\n      <td>0.000022</td>\n      <td>0.000558</td>\n      <td>0.000190</td>\n      <td>...</td>\n      <td>0.000105</td>\n      <td>0.026920</td>\n      <td>0.000213</td>\n      <td>0.000413</td>\n      <td>0.000000</td>\n      <td>0.011927</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000327</td>\n      <td>0.000199</td>\n    </tr>\n    <tr>\n      <th>misc</th>\n      <td>0.000452</td>\n      <td>0.000603</td>\n      <td>0.000411</td>\n      <td>0.000335</td>\n      <td>0.000529</td>\n      <td>0.001109</td>\n      <td>0.001035</td>\n      <td>0.001380</td>\n      <td>0.004913</td>\n      <td>0.000454</td>\n      <td>...</td>\n      <td>0.000398</td>\n      <td>0.003879</td>\n      <td>0.000176</td>\n      <td>0.005351</td>\n      <td>0.000929</td>\n      <td>0.001830</td>\n      <td>0.000000</td>\n      <td>0.000775</td>\n      <td>0.000446</td>\n      <td>0.000544</td>\n    </tr>\n    <tr>\n      <th>pop</th>\n      <td>0.000247</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000081</td>\n      <td>0.000254</td>\n      <td>0.000061</td>\n      <td>0.000029</td>\n      <td>0.000000</td>\n      <td>0.000417</td>\n      <td>0.000126</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.039320</td>\n      <td>0.000474</td>\n      <td>0.000832</td>\n      <td>0.000000</td>\n      <td>0.010012</td>\n      <td>0.000181</td>\n      <td>0.000000</td>\n      <td>0.000676</td>\n      <td>0.000655</td>\n    </tr>\n    <tr>\n      <th>rap</th>\n      <td>0.001971</td>\n      <td>0.000713</td>\n      <td>0.001026</td>\n      <td>0.000590</td>\n      <td>0.000286</td>\n      <td>0.000394</td>\n      <td>0.000298</td>\n      <td>0.000476</td>\n      <td>0.001011</td>\n      <td>0.000305</td>\n      <td>...</td>\n      <td>0.000224</td>\n      <td>0.016065</td>\n      <td>0.001182</td>\n      <td>0.001577</td>\n      <td>0.000075</td>\n      <td>0.002928</td>\n      <td>0.001504</td>\n      <td>0.000092</td>\n      <td>0.000961</td>\n      <td>0.003907</td>\n    </tr>\n    <tr>\n      <th>rb</th>\n      <td>0.000242</td>\n      <td>0.000341</td>\n      <td>0.000174</td>\n      <td>0.000320</td>\n      <td>0.000178</td>\n      <td>0.000117</td>\n      <td>0.000143</td>\n      <td>0.000213</td>\n      <td>0.000605</td>\n      <td>0.000014</td>\n      <td>...</td>\n      <td>0.000081</td>\n      <td>0.035421</td>\n      <td>0.000834</td>\n      <td>0.000330</td>\n      <td>0.000034</td>\n      <td>0.008876</td>\n      <td>0.000244</td>\n      <td>0.000000</td>\n      <td>0.000436</td>\n      <td>0.000832</td>\n    </tr>\n    <tr>\n      <th>rock</th>\n      <td>0.000148</td>\n      <td>0.000000</td>\n      <td>0.000157</td>\n      <td>0.000028</td>\n      <td>0.000153</td>\n      <td>0.000500</td>\n      <td>0.000105</td>\n      <td>0.000107</td>\n      <td>0.000355</td>\n      <td>0.000319</td>\n      <td>...</td>\n      <td>0.000070</td>\n      <td>0.026819</td>\n      <td>0.000188</td>\n      <td>0.000797</td>\n      <td>0.000235</td>\n      <td>0.011931</td>\n      <td>0.000056</td>\n      <td>0.000016</td>\n      <td>0.000540</td>\n      <td>0.000176</td>\n    </tr>\n  </tbody>\n</table>\n<p>6 rows × 6268 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"top_words_by_genre = {}\nfor genre in avg_tfidf_by_genre.index:\n    top_words_by_genre[genre] = avg_tfidf_by_genre.loc[genre].nlargest(50).index.tolist()","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:21:05.543219Z","iopub.execute_input":"2023-11-11T15:21:05.543618Z","iopub.status.idle":"2023-11-11T15:21:05.587564Z","shell.execute_reply.started":"2023-11-11T15:21:05.543577Z","shell.execute_reply":"2023-11-11T15:21:05.583160Z"},"trusted":true},"execution_count":386,"outputs":[]},{"cell_type":"code","source":"top_words_by_genre[\"country\"][:5], top_words_by_genre[\"rap\"][:5]","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:21:06.892385Z","iopub.execute_input":"2023-11-11T15:21:06.892834Z","iopub.status.idle":"2023-11-11T15:21:06.901632Z","shell.execute_reply.started":"2023-11-11T15:21:06.892808Z","shell.execute_reply":"2023-11-11T15:21:06.900195Z"},"trusted":true},"execution_count":387,"outputs":[{"execution_count":387,"output_type":"execute_result","data":{"text/plain":"(['love', 'time', 'one', 'youre', 'well'],\n ['nigga', 'get', 'got', 'shit', 'aint'])"},"metadata":{}}]},{"cell_type":"code","source":"selected_words = set()\nfor genre in top_words_by_genre:\n    for word in top_words_by_genre[genre]:\n        selected_words.add(word)\n        \nselected_words = list(selected_words)\nlen(selected_words)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:21:11.713172Z","iopub.execute_input":"2023-11-11T15:21:11.713663Z","iopub.status.idle":"2023-11-11T15:21:11.725657Z","shell.execute_reply.started":"2023-11-11T15:21:11.713636Z","shell.execute_reply":"2023-11-11T15:21:11.723178Z"},"trusted":true},"execution_count":388,"outputs":[{"execution_count":388,"output_type":"execute_result","data":{"text/plain":"110"},"metadata":{}}]},{"cell_type":"code","source":"data_df = undersampled_data.copy()\nbinary_df = pd.DataFrame(\n    columns = selected_words,\n    index=data_df.title\n)\n\nfor i in range(len(data_df)):\n    song_binary_list = [0]*len(selected_words)\n    for line_token in data_df[\"tokens\"].iloc[i]:\n        for token in line_token:\n            if token in selected_words:\n                word_idx = selected_words.index(token)\n                song_binary_list[word_idx] = 1\n    \n    song_binary_list = pd.DataFrame(\n            np.array(song_binary_list).reshape(1, -1),\n            columns=binary_df.columns\n        )\n    \n    binary_df.iloc[i] = song_binary_list;","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:21:14.629658Z","iopub.execute_input":"2023-11-11T15:21:14.629999Z","iopub.status.idle":"2023-11-11T15:21:27.132569Z","shell.execute_reply.started":"2023-11-11T15:21:14.629976Z","shell.execute_reply":"2023-11-11T15:21:27.129643Z"},"trusted":true},"execution_count":389,"outputs":[]},{"cell_type":"code","source":"binary_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:21:29.274376Z","iopub.execute_input":"2023-11-11T15:21:29.274837Z","iopub.status.idle":"2023-11-11T15:21:29.301801Z","shell.execute_reply.started":"2023-11-11T15:21:29.274798Z","shell.execute_reply":"2023-11-11T15:21:29.300119Z"},"trusted":true},"execution_count":390,"outputs":[{"execution_count":390,"output_type":"execute_result","data":{"text/plain":"                                  say mind nigga aint men fuck might cuz got  \\\ntitle                                                                          \nLove Me Like Im Not Made of Stone   0    0     0    0   0    0     0   0   0   \nMudstained Troubadour               0    0     0    0   0    0     0   0   0   \nA Day In The Country Full Text      1    0     0    0   0    0     1   0   1   \nMy Same                             1    0     0    1   0    0     0   0   0   \nRosalind Helen And Her Child        1    1     0    0   1    0     1   0   0   \n\n                                  girl  ... there fucking ever yall way god  \\\ntitle                                   ...                                   \nLove Me Like Im Not Made of Stone    0  ...     1       0    0    0   0   0   \nMudstained Troubadour                0  ...     0       1    1    0   1   0   \nA Day In The Country Full Text       1  ...     0       0    0    0   1   1   \nMy Same                              0  ...     0       0    0    0   1   0   \nRosalind Helen And Her Child         0  ...     0       0    1    0   1   1   \n\n                                  need cant night word  \ntitle                                                   \nLove Me Like Im Not Made of Stone    0    1     0    0  \nMudstained Troubadour                0    1     0    1  \nA Day In The Country Full Text       1    1     1    1  \nMy Same                              0    0     0    0  \nRosalind Helen And Her Child         1    0     1    1  \n\n[5 rows x 110 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>say</th>\n      <th>mind</th>\n      <th>nigga</th>\n      <th>aint</th>\n      <th>men</th>\n      <th>fuck</th>\n      <th>might</th>\n      <th>cuz</th>\n      <th>got</th>\n      <th>girl</th>\n      <th>...</th>\n      <th>there</th>\n      <th>fucking</th>\n      <th>ever</th>\n      <th>yall</th>\n      <th>way</th>\n      <th>god</th>\n      <th>need</th>\n      <th>cant</th>\n      <th>night</th>\n      <th>word</th>\n    </tr>\n    <tr>\n      <th>title</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Love Me Like Im Not Made of Stone</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Mudstained Troubadour</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>A Day In The Country Full Text</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>My Same</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Rosalind Helen And Her Child</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 110 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"final_df = data_df.merge(\n    right=binary_df,\n    left_on=\"title\",\n    right_index=True\n)\nfinal_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:21:34.274977Z","iopub.execute_input":"2023-11-11T15:21:34.275678Z","iopub.status.idle":"2023-11-11T15:21:34.528716Z","shell.execute_reply.started":"2023-11-11T15:21:34.275649Z","shell.execute_reply":"2023-11-11T15:21:34.526941Z"},"trusted":true},"execution_count":391,"outputs":[{"execution_count":391,"output_type":"execute_result","data":{"text/plain":"                               title                artist   tag  \\\n0  Love Me Like Im Not Made of Stone              Lykke Li  rock   \n1              Mudstained Troubadour                Opaque   rap   \n2     A Day In The Country Full Text         Anton Chekhov  misc   \n3                            My Same                 Adele   pop   \n4       Rosalind Helen And Her Child  Percy Bysshe Shelley  misc   \n\n                                              lyrics  \\\n0   \\n there heart cannot hide \\n there beat cant...   \n1   \\n walk mud knee cloudy dark \\n spark start b...   \n2   \\n dark leadencoloured mass creeping sky towa...   \n3   \\n aye aye ayeaye \\n aye aye ayeaye \\n aye ay...   \n4   \\n helen \\n come hither sweet rosalind \\n ti ...   \n\n                                               lines  \\\n0  [there heart cannot hide, there beat cant deny...   \n1  [walk mud knee cloudy dark, spark start bark a...   \n2  [dark leadencoloured mass creeping sky towards...   \n3  [aye aye ayeaye, aye aye ayeaye, aye aye ayeay...   \n4  [helen, come hither sweet rosalind, ti long si...   \n\n                                              tokens  total_lines  total_word  \\\n0  [[there, heart, can, not, hide], [there, beat,...         29.0       121.0   \n1  [[walk, mud, knee, cloudy, dark], [spark, star...         55.0       276.0   \n2  [[dark, leadencoloured, mass, creeping, sky, t...         65.0      1131.0   \n3  [[aye, aye, ayeaye], [aye, aye, ayeaye], [aye,...         40.0       164.0   \n4  [[helen], [come, hither, sweet, rosalind], [ti...       1333.0      4848.0   \n\n   unique_words  total_chars  ...  there  fucking  ever  yall  way god need  \\\n0          48.0        504.0  ...      1        0     0     0    0   0    0   \n1         244.0       1407.0  ...      0        1     1     0    1   0    0   \n2         620.0       6125.0  ...      0        0     0     0    1   1    1   \n3          65.0        826.0  ...      0        0     0     0    1   0    0   \n4        1762.0      25125.0  ...      0        0     1     0    1   1    1   \n\n  cant night word  \n0    1     0    0  \n1    1     0    1  \n2    1     1    1  \n3    0     0    0  \n4    0     1    1  \n\n[5 rows x 126 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>artist</th>\n      <th>tag</th>\n      <th>lyrics</th>\n      <th>lines</th>\n      <th>tokens</th>\n      <th>total_lines</th>\n      <th>total_word</th>\n      <th>unique_words</th>\n      <th>total_chars</th>\n      <th>...</th>\n      <th>there</th>\n      <th>fucking</th>\n      <th>ever</th>\n      <th>yall</th>\n      <th>way</th>\n      <th>god</th>\n      <th>need</th>\n      <th>cant</th>\n      <th>night</th>\n      <th>word</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Love Me Like Im Not Made of Stone</td>\n      <td>Lykke Li</td>\n      <td>rock</td>\n      <td>\\n there heart cannot hide \\n there beat cant...</td>\n      <td>[there heart cannot hide, there beat cant deny...</td>\n      <td>[[there, heart, can, not, hide], [there, beat,...</td>\n      <td>29.0</td>\n      <td>121.0</td>\n      <td>48.0</td>\n      <td>504.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Mudstained Troubadour</td>\n      <td>Opaque</td>\n      <td>rap</td>\n      <td>\\n walk mud knee cloudy dark \\n spark start b...</td>\n      <td>[walk mud knee cloudy dark, spark start bark a...</td>\n      <td>[[walk, mud, knee, cloudy, dark], [spark, star...</td>\n      <td>55.0</td>\n      <td>276.0</td>\n      <td>244.0</td>\n      <td>1407.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A Day In The Country Full Text</td>\n      <td>Anton Chekhov</td>\n      <td>misc</td>\n      <td>\\n dark leadencoloured mass creeping sky towa...</td>\n      <td>[dark leadencoloured mass creeping sky towards...</td>\n      <td>[[dark, leadencoloured, mass, creeping, sky, t...</td>\n      <td>65.0</td>\n      <td>1131.0</td>\n      <td>620.0</td>\n      <td>6125.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>My Same</td>\n      <td>Adele</td>\n      <td>pop</td>\n      <td>\\n aye aye ayeaye \\n aye aye ayeaye \\n aye ay...</td>\n      <td>[aye aye ayeaye, aye aye ayeaye, aye aye ayeay...</td>\n      <td>[[aye, aye, ayeaye], [aye, aye, ayeaye], [aye,...</td>\n      <td>40.0</td>\n      <td>164.0</td>\n      <td>65.0</td>\n      <td>826.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Rosalind Helen And Her Child</td>\n      <td>Percy Bysshe Shelley</td>\n      <td>misc</td>\n      <td>\\n helen \\n come hither sweet rosalind \\n ti ...</td>\n      <td>[helen, come hither sweet rosalind, ti long si...</td>\n      <td>[[helen], [come, hither, sweet, rosalind], [ti...</td>\n      <td>1333.0</td>\n      <td>4848.0</td>\n      <td>1762.0</td>\n      <td>25125.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 126 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.model_selection import GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:21:39.484643Z","iopub.execute_input":"2023-11-11T15:21:39.484984Z","iopub.status.idle":"2023-11-11T15:21:39.493325Z","shell.execute_reply.started":"2023-11-11T15:21:39.484960Z","shell.execute_reply":"2023-11-11T15:21:39.492122Z"},"trusted":true},"execution_count":392,"outputs":[]},{"cell_type":"markdown","source":"## Base Model","metadata":{}},{"cell_type":"code","source":"data = final_df.dropna()\nx, y = data.drop([\"title\", \"artist\", \"tag\", \"lyrics\", \"lines\", \"tokens\"], axis=1), data.tag \nx_train, x_test, y_train, y_test = train_test_split(\n    x, y,\n    random_state=42\n)\n\nprint(x_train.shape, x_test.shape)\n\npca = PCA(n_components=30)\nx_train = pca.fit_transform(x_train)\nx_test = pca.transform(x_test)\n\nmodel = LogisticRegressionCV(cv=3, max_iter=200, solver=\"newton-cholesky\").fit(x_train, y_train)\npreds = model.predict(x_test)\n\nprint(accuracy_score(y_test, preds))\nprint(f1_score(y_test, preds, average=\"weighted\"))","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:21:51.559129Z","iopub.execute_input":"2023-11-11T15:21:51.559611Z","iopub.status.idle":"2023-11-11T15:21:57.211244Z","shell.execute_reply.started":"2023-11-11T15:21:51.559580Z","shell.execute_reply":"2023-11-11T15:21:57.210365Z"},"trusted":true},"execution_count":393,"outputs":[{"name":"stdout","text":"(19821, 120) (6608, 120)\n0.5196731234866828\n0.5101286764515212\n","output_type":"stream"}]},{"cell_type":"code","source":"def performGridSearch(x_train, y_train, x_test, y_test, model, param_grid, cv=3):\n    grid_search = GridSearchCV(model, param_grid, cv=cv, verbose=2)\n    grid_search.fit(x_train, y_train)\n    \n    best_params = grid_search.best_params_\n    best_model = grid_search.best_estimator_\n    \n    preds = best_model.predict(x_test)\n    \n    print(best_params)\n    return f1_score(y_test, preds, average=\"weighted\")","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:22:22.475710Z","iopub.execute_input":"2023-11-11T15:22:22.476094Z","iopub.status.idle":"2023-11-11T15:22:22.484911Z","shell.execute_reply.started":"2023-11-11T15:22:22.476061Z","shell.execute_reply":"2023-11-11T15:22:22.483194Z"},"trusted":true},"execution_count":395,"outputs":[]},{"cell_type":"markdown","source":"### Tuning Models","metadata":{}},{"cell_type":"code","source":"model = RandomForestClassifier()\nparam_grid = {\n    \"n_estimators\": [50, 100, 200],\n    \"criterion\": [\"gini\", \"log_loss\"],\n    \"max_depth\":[None, 3, 10],\n    \"max_features\": [\"log2\", None]\n}\n\nperformGridSearch(x_train, y_train, x_test, y_test, model, param_grid, cv=1)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T13:21:16.880108Z","iopub.execute_input":"2023-11-11T13:21:16.880592Z","iopub.status.idle":"2023-11-11T13:25:50.573651Z","shell.execute_reply.started":"2023-11-11T13:21:16.880563Z","shell.execute_reply":"2023-11-11T13:25:50.570195Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":149,"outputs":[{"name":"stdout","text":"Fitting 2 folds for each of 36 candidates, totalling 72 fits\n[CV] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50; total time=   2.3s\n[CV] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50; total time=   2.3s\n[CV] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100; total time=   4.5s\n[CV] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100; total time=   4.7s\n[CV] END criterion=gini, max_depth=None, max_features=log2, n_estimators=200; total time=   9.3s\n[CV] END criterion=gini, max_depth=None, max_features=log2, n_estimators=200; total time=   9.3s\n[CV] END criterion=gini, max_depth=None, max_features=None, n_estimators=50; total time=  13.6s\n[CV] END criterion=gini, max_depth=None, max_features=None, n_estimators=50; total time=  13.9s\n[CV] END criterion=gini, max_depth=None, max_features=None, n_estimators=100; total time=  27.2s\n[CV] END criterion=gini, max_depth=None, max_features=None, n_estimators=100; total time=  27.7s\n[CV] END criterion=gini, max_depth=None, max_features=None, n_estimators=200; total time=  54.7s\n[CV] END criterion=gini, max_depth=None, max_features=None, n_estimators=200; total time=  55.4s\n[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50; total time=   0.7s\n[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50; total time=   0.7s\n[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100; total time=   1.5s\n[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100; total time=   1.5s\n[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=200; total time=   2.9s\n[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=200; total time=   2.9s\n[CV] END criterion=gini, max_depth=3, max_features=None, n_estimators=50; total time=   3.8s\n[CV] END criterion=gini, max_depth=3, max_features=None, n_estimators=50; total time=   3.8s\n[CV] END criterion=gini, max_depth=3, max_features=None, n_estimators=100; total time=   7.6s\n[CV] END criterion=gini, max_depth=3, max_features=None, n_estimators=100; total time=   7.6s\n[CV] END criterion=gini, max_depth=3, max_features=None, n_estimators=200; total time=  15.1s\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[149], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier()\n\u001b[1;32m      2\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgini\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_features\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m      7\u001b[0m }\n\u001b[0;32m----> 9\u001b[0m \u001b[43mperformGridSearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[148], line 3\u001b[0m, in \u001b[0;36mperformGridSearch\u001b[0;34m(x_train, y_train, x_test, y_test, model, param_grid, cv)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperformGridSearch\u001b[39m(x_train, y_train, x_test, y_test, model, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m      2\u001b[0m     grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(model, param_grid, cv\u001b[38;5;241m=\u001b[39mcv, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[1;32m      6\u001b[0m     best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    182\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 184\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"model = MLPClassifier()\nparam_grid = {\n    \"hidden_layer_sizes\": [(50), (100), (200), (100, 100), (200, 200)],\n    \"alpha\": [0.0001, 0.01],\n    \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"]\n}\n\nperformGridSearch(x_train, y_train, x_test, y_test, model, param_grid, cv=2)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T13:26:03.901357Z","iopub.execute_input":"2023-11-11T13:26:03.901811Z","iopub.status.idle":"2023-11-11T13:32:13.176925Z","shell.execute_reply.started":"2023-11-11T13:26:03.901784Z","shell.execute_reply":"2023-11-11T13:32:13.176072Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":150,"outputs":[{"name":"stdout","text":"Fitting 2 folds for each of 30 candidates, totalling 60 fits\n[CV] END alpha=0.0001, hidden_layer_sizes=50, learning_rate=constant; total time=   1.4s\n[CV] END alpha=0.0001, hidden_layer_sizes=50, learning_rate=constant; total time=   1.6s\n[CV] END alpha=0.0001, hidden_layer_sizes=50, learning_rate=invscaling; total time=   1.9s\n[CV] END alpha=0.0001, hidden_layer_sizes=50, learning_rate=invscaling; total time=   1.6s\n[CV] END alpha=0.0001, hidden_layer_sizes=50, learning_rate=adaptive; total time=   1.6s\n[CV] END alpha=0.0001, hidden_layer_sizes=50, learning_rate=adaptive; total time=   1.2s\n[CV] END alpha=0.0001, hidden_layer_sizes=100, learning_rate=constant; total time=   1.8s\n[CV] END alpha=0.0001, hidden_layer_sizes=100, learning_rate=constant; total time=   2.1s\n[CV] END alpha=0.0001, hidden_layer_sizes=100, learning_rate=invscaling; total time=   1.8s\n[CV] END alpha=0.0001, hidden_layer_sizes=100, learning_rate=invscaling; total time=   1.1s\n[CV] END alpha=0.0001, hidden_layer_sizes=100, learning_rate=adaptive; total time=   1.3s\n[CV] END alpha=0.0001, hidden_layer_sizes=100, learning_rate=adaptive; total time=   2.9s\n[CV] END alpha=0.0001, hidden_layer_sizes=200, learning_rate=constant; total time=   2.5s\n[CV] END alpha=0.0001, hidden_layer_sizes=200, learning_rate=constant; total time=   4.6s\n[CV] END alpha=0.0001, hidden_layer_sizes=200, learning_rate=invscaling; total time=   1.8s\n[CV] END alpha=0.0001, hidden_layer_sizes=200, learning_rate=invscaling; total time=   1.5s\n[CV] END alpha=0.0001, hidden_layer_sizes=200, learning_rate=adaptive; total time=   2.5s\n[CV] END alpha=0.0001, hidden_layer_sizes=200, learning_rate=adaptive; total time=   1.6s\n[CV] END alpha=0.0001, hidden_layer_sizes=(100, 100), learning_rate=constant; total time=   9.6s\n[CV] END alpha=0.0001, hidden_layer_sizes=(100, 100), learning_rate=constant; total time=   3.4s\n[CV] END alpha=0.0001, hidden_layer_sizes=(100, 100), learning_rate=invscaling; total time=   4.2s\n[CV] END alpha=0.0001, hidden_layer_sizes=(100, 100), learning_rate=invscaling; total time=   3.4s\n[CV] END alpha=0.0001, hidden_layer_sizes=(100, 100), learning_rate=adaptive; total time=   3.6s\n[CV] END alpha=0.0001, hidden_layer_sizes=(100, 100), learning_rate=adaptive; total time=   3.5s\n[CV] END alpha=0.0001, hidden_layer_sizes=(200, 200), learning_rate=constant; total time=   6.6s\n[CV] END alpha=0.0001, hidden_layer_sizes=(200, 200), learning_rate=constant; total time=   8.7s\n[CV] END alpha=0.0001, hidden_layer_sizes=(200, 200), learning_rate=invscaling; total time=  19.1s\n[CV] END alpha=0.0001, hidden_layer_sizes=(200, 200), learning_rate=invscaling; total time=  21.4s\n[CV] END alpha=0.0001, hidden_layer_sizes=(200, 200), learning_rate=adaptive; total time=  19.6s\n[CV] END alpha=0.0001, hidden_layer_sizes=(200, 200), learning_rate=adaptive; total time=   6.5s\n[CV] END alpha=0.01, hidden_layer_sizes=50, learning_rate=constant; total time=   3.2s\n[CV] END alpha=0.01, hidden_layer_sizes=50, learning_rate=constant; total time=   2.0s\n[CV] END alpha=0.01, hidden_layer_sizes=50, learning_rate=invscaling; total time=   1.5s\n[CV] END alpha=0.01, hidden_layer_sizes=50, learning_rate=invscaling; total time=   1.9s\n[CV] END alpha=0.01, hidden_layer_sizes=50, learning_rate=adaptive; total time=   1.8s\n[CV] END alpha=0.01, hidden_layer_sizes=50, learning_rate=adaptive; total time=   2.0s\n[CV] END alpha=0.01, hidden_layer_sizes=100, learning_rate=constant; total time=   1.6s\n[CV] END alpha=0.01, hidden_layer_sizes=100, learning_rate=constant; total time=   2.1s\n[CV] END alpha=0.01, hidden_layer_sizes=100, learning_rate=invscaling; total time=   1.8s\n[CV] END alpha=0.01, hidden_layer_sizes=100, learning_rate=invscaling; total time=   1.9s\n[CV] END alpha=0.01, hidden_layer_sizes=100, learning_rate=adaptive; total time=   2.7s\n[CV] END alpha=0.01, hidden_layer_sizes=100, learning_rate=adaptive; total time=   1.4s\n[CV] END alpha=0.01, hidden_layer_sizes=200, learning_rate=constant; total time=   1.3s\n[CV] END alpha=0.01, hidden_layer_sizes=200, learning_rate=constant; total time=   1.7s\n[CV] END alpha=0.01, hidden_layer_sizes=200, learning_rate=invscaling; total time=   1.7s\n[CV] END alpha=0.01, hidden_layer_sizes=200, learning_rate=invscaling; total time=   2.2s\n[CV] END alpha=0.01, hidden_layer_sizes=200, learning_rate=adaptive; total time=   2.3s\n[CV] END alpha=0.01, hidden_layer_sizes=200, learning_rate=adaptive; total time=   2.3s\n[CV] END alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=constant; total time=   1.6s\n[CV] END alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=constant; total time=   2.7s\n[CV] END alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=invscaling; total time=   6.5s\n[CV] END alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=invscaling; total time=   4.1s\n[CV] END alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=adaptive; total time=   7.3s\n[CV] END alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=adaptive; total time=   4.1s\n[CV] END alpha=0.01, hidden_layer_sizes=(200, 200), learning_rate=constant; total time=   7.5s\n[CV] END alpha=0.01, hidden_layer_sizes=(200, 200), learning_rate=constant; total time=   7.3s\n[CV] END alpha=0.01, hidden_layer_sizes=(200, 200), learning_rate=invscaling; total time=  13.2s\n[CV] END alpha=0.01, hidden_layer_sizes=(200, 200), learning_rate=invscaling; total time=  15.6s\n[CV] END alpha=0.01, hidden_layer_sizes=(200, 200), learning_rate=adaptive; total time=  21.1s\n[CV] END alpha=0.01, hidden_layer_sizes=(200, 200), learning_rate=adaptive; total time=   7.6s\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":150,"output_type":"execute_result","data":{"text/plain":"0.5209727632041241"},"metadata":{}}]},{"cell_type":"code","source":"model = KNeighborsClassifier()\nparam_grid = {\n    \"n_neighbors\": [3, 5, 10, 20],\n    \"leaf_size\": [10, 30, 100]\n}\n\nperformGridSearch(x_train, y_train, x_test, y_test, model, param_grid, cv=2)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:22:29.117480Z","iopub.execute_input":"2023-11-11T15:22:29.118055Z","iopub.status.idle":"2023-11-11T15:22:44.574768Z","shell.execute_reply.started":"2023-11-11T15:22:29.118013Z","shell.execute_reply":"2023-11-11T15:22:44.572309Z"},"trusted":true},"execution_count":396,"outputs":[{"name":"stdout","text":"Fitting 2 folds for each of 12 candidates, totalling 24 fits\n[CV] END ........................leaf_size=10, n_neighbors=3; total time=   0.6s\n[CV] END ........................leaf_size=10, n_neighbors=3; total time=   0.6s\n[CV] END ........................leaf_size=10, n_neighbors=5; total time=   0.6s\n[CV] END ........................leaf_size=10, n_neighbors=5; total time=   0.6s\n[CV] END .......................leaf_size=10, n_neighbors=10; total time=   0.6s\n[CV] END .......................leaf_size=10, n_neighbors=10; total time=   0.6s\n[CV] END .......................leaf_size=10, n_neighbors=20; total time=   0.6s\n[CV] END .......................leaf_size=10, n_neighbors=20; total time=   0.6s\n[CV] END ........................leaf_size=30, n_neighbors=3; total time=   0.6s\n[CV] END ........................leaf_size=30, n_neighbors=3; total time=   0.6s\n[CV] END ........................leaf_size=30, n_neighbors=5; total time=   0.6s\n[CV] END ........................leaf_size=30, n_neighbors=5; total time=   0.6s\n[CV] END .......................leaf_size=30, n_neighbors=10; total time=   0.6s\n[CV] END .......................leaf_size=30, n_neighbors=10; total time=   0.6s\n[CV] END .......................leaf_size=30, n_neighbors=20; total time=   0.6s\n[CV] END .......................leaf_size=30, n_neighbors=20; total time=   0.6s\n[CV] END .......................leaf_size=100, n_neighbors=3; total time=   0.6s\n[CV] END .......................leaf_size=100, n_neighbors=3; total time=   0.6s\n[CV] END .......................leaf_size=100, n_neighbors=5; total time=   0.6s\n[CV] END .......................leaf_size=100, n_neighbors=5; total time=   0.6s\n[CV] END ......................leaf_size=100, n_neighbors=10; total time=   0.6s\n[CV] END ......................leaf_size=100, n_neighbors=10; total time=   0.7s\n[CV] END ......................leaf_size=100, n_neighbors=20; total time=   0.8s\n[CV] END ......................leaf_size=100, n_neighbors=20; total time=   0.6s\n{'leaf_size': 10, 'n_neighbors': 3}\n","output_type":"stream"},{"execution_count":396,"output_type":"execute_result","data":{"text/plain":"0.5454023199597815"},"metadata":{}}]},{"cell_type":"code","source":"model = SVC()\nparam_grid = {\n    \"C\": [0.5, 1, 2],\n    \"gamma\": [\"scale\", \"auto\"],\n    \"degree\": [1, 3, 5],\n    \"class_weight\": [None, \"balanced\"]\n}\n\nperformGridSearch(x_train, y_train, x_test, y_test, model, param_grid, cv=2)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T13:32:28.132483Z","iopub.execute_input":"2023-11-11T13:32:28.132994Z","iopub.status.idle":"2023-11-11T13:51:28.640767Z","shell.execute_reply.started":"2023-11-11T13:32:28.132964Z","shell.execute_reply":"2023-11-11T13:51:28.638090Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":152,"outputs":[{"name":"stdout","text":"Fitting 2 folds for each of 36 candidates, totalling 72 fits\n[CV] END ....C=0.5, class_weight=None, degree=1, gamma=scale; total time=  10.6s\n[CV] END ....C=0.5, class_weight=None, degree=1, gamma=scale; total time=  10.6s\n[CV] END .....C=0.5, class_weight=None, degree=1, gamma=auto; total time=  20.4s\n[CV] END .....C=0.5, class_weight=None, degree=1, gamma=auto; total time=  20.6s\n[CV] END ....C=0.5, class_weight=None, degree=3, gamma=scale; total time=  10.5s\n[CV] END ....C=0.5, class_weight=None, degree=3, gamma=scale; total time=  10.3s\n[CV] END .....C=0.5, class_weight=None, degree=3, gamma=auto; total time=  20.3s\n[CV] END .....C=0.5, class_weight=None, degree=3, gamma=auto; total time=  20.4s\n[CV] END ....C=0.5, class_weight=None, degree=5, gamma=scale; total time=  10.2s\n[CV] END ....C=0.5, class_weight=None, degree=5, gamma=scale; total time=  10.4s\n[CV] END .....C=0.5, class_weight=None, degree=5, gamma=auto; total time=  20.2s\n[CV] END .....C=0.5, class_weight=None, degree=5, gamma=auto; total time=  20.3s\n[CV] END C=0.5, class_weight=balanced, degree=1, gamma=scale; total time=  10.7s\n[CV] END C=0.5, class_weight=balanced, degree=1, gamma=scale; total time=  10.9s\n[CV] END .C=0.5, class_weight=balanced, degree=1, gamma=auto; total time=  19.9s\n[CV] END C=0.5, class_weight=balanced, degree=3, gamma=scale; total time=  10.7s\n[CV] END C=0.5, class_weight=balanced, degree=3, gamma=scale; total time=  10.9s\n[CV] END .C=0.5, class_weight=balanced, degree=3, gamma=auto; total time=  19.9s\n[CV] END .C=0.5, class_weight=balanced, degree=3, gamma=auto; total time=  20.0s\n[CV] END C=0.5, class_weight=balanced, degree=5, gamma=scale; total time=  10.9s\n[CV] END C=0.5, class_weight=balanced, degree=5, gamma=scale; total time=  10.9s\n[CV] END .C=0.5, class_weight=balanced, degree=5, gamma=auto; total time=  20.0s\n[CV] END .C=0.5, class_weight=balanced, degree=5, gamma=auto; total time=  20.3s\n[CV] END ......C=1, class_weight=None, degree=1, gamma=scale; total time=  10.0s\n[CV] END ......C=1, class_weight=None, degree=1, gamma=scale; total time=  10.1s\n[CV] END .......C=1, class_weight=None, degree=1, gamma=auto; total time=  20.8s\n[CV] END .......C=1, class_weight=None, degree=1, gamma=auto; total time=  20.9s\n[CV] END ......C=1, class_weight=None, degree=3, gamma=scale; total time=  10.0s\n[CV] END ......C=1, class_weight=None, degree=3, gamma=scale; total time=  10.1s\n[CV] END .......C=1, class_weight=None, degree=3, gamma=auto; total time=  21.4s\n[CV] END .......C=1, class_weight=None, degree=3, gamma=auto; total time=  21.0s\n[CV] END ......C=1, class_weight=None, degree=5, gamma=scale; total time=  10.1s\n[CV] END ......C=1, class_weight=None, degree=5, gamma=scale; total time=  10.1s\n[CV] END .......C=1, class_weight=None, degree=5, gamma=auto; total time=  20.7s\n[CV] END .......C=1, class_weight=None, degree=5, gamma=auto; total time=  20.8s\n[CV] END ..C=1, class_weight=balanced, degree=1, gamma=scale; total time=  10.6s\n[CV] END ..C=1, class_weight=balanced, degree=1, gamma=scale; total time=  10.8s\n[CV] END ...C=1, class_weight=balanced, degree=1, gamma=auto; total time=  20.5s\n[CV] END ...C=1, class_weight=balanced, degree=1, gamma=auto; total time=  20.7s\n[CV] END ..C=1, class_weight=balanced, degree=3, gamma=scale; total time=  10.6s\n[CV] END ..C=1, class_weight=balanced, degree=3, gamma=scale; total time=  10.9s\n[CV] END ...C=1, class_weight=balanced, degree=3, gamma=auto; total time=  20.6s\n[CV] END ...C=1, class_weight=balanced, degree=3, gamma=auto; total time=  20.7s\n[CV] END ..C=1, class_weight=balanced, degree=5, gamma=scale; total time=  10.5s\n[CV] END ..C=1, class_weight=balanced, degree=5, gamma=scale; total time=  10.7s\n[CV] END ...C=1, class_weight=balanced, degree=5, gamma=auto; total time=  20.5s\n[CV] END ...C=1, class_weight=balanced, degree=5, gamma=auto; total time=  20.7s\n[CV] END ......C=2, class_weight=None, degree=1, gamma=scale; total time=   9.9s\n[CV] END ......C=2, class_weight=None, degree=1, gamma=scale; total time=  10.1s\n[CV] END .......C=2, class_weight=None, degree=1, gamma=auto; total time=  20.5s\n[CV] END .......C=2, class_weight=None, degree=1, gamma=auto; total time=  20.5s\n[CV] END ......C=2, class_weight=None, degree=3, gamma=scale; total time=   9.8s\n[CV] END ......C=2, class_weight=None, degree=3, gamma=scale; total time=   9.9s\n[CV] END .......C=2, class_weight=None, degree=3, gamma=auto; total time=  20.5s\n[CV] END .......C=2, class_weight=None, degree=3, gamma=auto; total time=  20.6s\n[CV] END ......C=2, class_weight=None, degree=5, gamma=scale; total time=   9.7s\n[CV] END ......C=2, class_weight=None, degree=5, gamma=scale; total time=   9.9s\n[CV] END .......C=2, class_weight=None, degree=5, gamma=auto; total time=  20.5s\n[CV] END .......C=2, class_weight=None, degree=5, gamma=auto; total time=  20.4s\n[CV] END ..C=2, class_weight=balanced, degree=1, gamma=scale; total time=  10.3s\n[CV] END ..C=2, class_weight=balanced, degree=1, gamma=scale; total time=  10.6s\n[CV] END ...C=2, class_weight=balanced, degree=1, gamma=auto; total time=  20.5s\n[CV] END ...C=2, class_weight=balanced, degree=1, gamma=auto; total time=  20.7s\n[CV] END ..C=2, class_weight=balanced, degree=3, gamma=scale; total time=  10.4s\n[CV] END ..C=2, class_weight=balanced, degree=3, gamma=scale; total time=  10.5s\n[CV] END ...C=2, class_weight=balanced, degree=3, gamma=auto; total time=  20.5s\n[CV] END ...C=2, class_weight=balanced, degree=3, gamma=auto; total time=  20.5s\n[CV] END ..C=2, class_weight=balanced, degree=5, gamma=scale; total time=  11.4s\n[CV] END ..C=2, class_weight=balanced, degree=5, gamma=scale; total time=  10.6s\n[CV] END ...C=2, class_weight=balanced, degree=5, gamma=auto; total time=  20.6s\n[CV] END ...C=2, class_weight=balanced, degree=5, gamma=auto; total time=  20.4s\n","output_type":"stream"},{"execution_count":152,"output_type":"execute_result","data":{"text/plain":"0.4043476918884171"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}